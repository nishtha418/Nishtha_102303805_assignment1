{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8182e6-7e72-46c4-ad80-cbdde277b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6003a1d-ad60-4d20-b095-1922b0fdc978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ques 1 \n",
    "#part[i]\n",
    "# Step 2: Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to DataFrame for clarity\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ee638c-63ff-45a6-9bac-3d8c72da1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf39fa5-18ad-40f3-895b-040618c60036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Implement Gaussian Naïve Bayes manually\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y) #Finds all classes present in training labels and stores them\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.prior = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c] = X_c.var(axis=0)\n",
    "            self.prior[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def calculate_likelihood(self, mean, var, x):\n",
    "        eps = 1e-6  # small number to prevent divide by zero\n",
    "        coeff = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n",
    "        exponent = np.exp(-(x - mean) ** 2 / (2 * var + eps))\n",
    "        return coeff * exponent\n",
    "\n",
    "    def calculate_posterior(self, x):\n",
    "        posteriors = []\n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.prior[c])\n",
    "            likelihood = np.sum(np.log(self.calculate_likelihood(self.mean[c], self.var[c], x)))\n",
    "            posterior = prior + likelihood\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.calculate_posterior(x) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be7a6fe-fb5d-4148-9c06-924eb2f3e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Manual): 0.9777777777777777\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train and test manual Gaussian Naïve Bayes model\n",
    "gnb_manual = GaussianNaiveBayes()\n",
    "gnb_manual.fit(X_train, y_train)\n",
    "y_pred_manual = gnb_manual.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (Manual):\", accuracy_score(y_test, y_pred_manual))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_manual))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_manual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288d2e91-65eb-47a3-9019-0102026bfdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (In-built): 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# part[ii]\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Step 1: Create model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Step 2: Train model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "print(\"Accuracy (In-built):\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caec8be-1622-4ead-bb87-35c01fc2d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value: {'n_neighbors': 3}\n",
      "Best cross-validation accuracy: 0.9583333333333334\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ques 2:\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "from sklearn.datasets import load_iris          # to load the Iris dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data        # features (sepal length, width, etc.)\n",
    "y = iris.target      # labels (0 = Setosa, 1 = Versicolor, 2 = Virginica)\n",
    "\n",
    "# Step 3: Split dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Define the model (KNN classifier)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Step 5: Define the parameter grid — values of K to try\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Step 6: Create the GridSearchCV object\n",
    "# cv=5 means 5-fold cross-validation\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 7: Fit (train) the GridSearchCV on the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Print the best parameter and corresponding accuracy\n",
    "print(\"Best K value:\", grid.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
    "\n",
    "# Step 9: Evaluate the best model on the test set\n",
    "best_knn = grid.best_estimator_          # get the best model found by GridSearchCV\n",
    "y_pred = best_knn.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828d5af-73ce-4cdf-a60d-da709a9a25ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
