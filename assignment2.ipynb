{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aafcc6f-247a-481d-a115-d6a1f03adf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# part 1\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# View first few rows\n",
    "df.head()\n",
    "\n",
    "# Select important attributes only\n",
    "selected_features = ['BirthDate', 'Education', 'Occupation', 'Gender', \n",
    "                     'MaritalStatus', 'HomeOwnerFlag', 'NumberCarsOwned', \n",
    "                     'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "df_selected.head()\n",
    "\n",
    "# Drop BirthDate \n",
    "df_selected = df_selected.drop('BirthDate', axis=1)\n",
    "\n",
    "df_selected.to_csv(\"Selected_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# part 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d37184-1184-4e07-8076-5d86c4cece1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
      "Categorical columns: ['Education', 'Occupation', 'Gender', 'MaritalStatus']\n"
     ]
    }
   ],
   "source": [
    "# Part II\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, KBinsDiscretizer, OneHotEncoder\n",
    "\n",
    "# Load your selected data from Part I\n",
    "df = pd.read_csv(\"Selected_data.csv\")\n",
    "\n",
    "# Identify numeric and categorical attributes\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765fe22b-b097-4e73-8764-4f3bcfb837d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(a) Null values handled successfully.\n"
     ]
    }
   ],
   "source": [
    "# ques2 a\n",
    "\n",
    "# (a) Handling Null Values\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "df_numeric_filled = pd.DataFrame(num_imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
    "df_categorical_filled = pd.DataFrame(cat_imputer.fit_transform(df[cat_cols]), columns=cat_cols)\n",
    "\n",
    "# Combine results\n",
    "df_a = pd.concat([df_numeric_filled, df_categorical_filled], axis=1)\n",
    "print(\"\\n(a) Null values handled successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30355e5-ecb6-4584-8737-d1e19ae7e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(b) Normalization applied (0–1 scale).\n"
     ]
    }
   ],
   "source": [
    "# (b) Normalization (Min-Max Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_a[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# Keep categorical as is\n",
    "df_b = pd.concat([df_normalized, df_a[cat_cols]], axis=1)\n",
    "print(\"\\n(b) Normalization applied (0–1 scale).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79b1ca2-0f68-4c56-9bf0-16d5d11fc7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(c) Discretization applied on continuous attributes (e.g., YearlyIncome).\n"
     ]
    }
   ],
   "source": [
    "# (c) Discretization (Binning) on Continuous Attributes\n",
    "df_c = df_b.copy()\n",
    "\n",
    "# Example: Discretize YearlyIncome into 5 bins\n",
    "if \"YearlyIncome\" in df_c.columns:\n",
    "    df_c[\"YearlyIncome_Bin\"] = pd.qcut(df_c[\"YearlyIncome\"], q=5, labels=[\"Very Low\",\"Low\",\"Medium\",\"High\",\"Very High\"])\n",
    "\n",
    "print(\"\\n(c) Discretization applied on continuous attributes (e.g., YearlyIncome).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace90f0e-49cd-4f80-8f79-5b62e7a6eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(d) Standardization applied (mean=0, std=1).\n"
     ]
    }
   ],
   "source": [
    "# (d) Standardization (Z-score)\n",
    "standard_scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(standard_scaler.fit_transform(df_a[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# Keep categorical same\n",
    "df_d = pd.concat([df_standardized, df_a[cat_cols]], axis=1)\n",
    "print(\"\\n(d) Standardization applied (mean=0, std=1).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b175d66-f786-4146-ad22-729b00be9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(e) Binarization done (One-Hot Encoding applied).\n"
     ]
    }
   ],
   "source": [
    "# (e) Binarization (One-Hot Encoding)\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=None, handle_unknown='ignore')\n",
    "encoded_array = encoder.fit_transform(df_a[cat_cols])\n",
    "encoded_cols = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "df_encoded = pd.DataFrame(encoded_array, columns=encoded_cols)\n",
    "df_e = pd.concat([df_a[numeric_cols], df_encoded], axis=1)\n",
    "\n",
    "print(\"\\n(e) Binarization done (One-Hot Encoding applied).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5bedfc-dc84-4faf-b654-0cf5308a9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Matching Similarity: 0.7\n",
      "Jaccard Similarity: 0.6666666666666666\n",
      "Cosine Similarity: 0.5781102513793457\n",
      "CommuteDistance column not found in dataset\n"
     ]
    }
   ],
   "source": [
    "# Part III:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- Load preprocessed data ---\n",
    "df = pd.read_csv(\"Selected_data.csv\")  # your selected features\n",
    "\n",
    "# --- Identify numeric and categorical columns ---\n",
    "numeric_cols = ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
    "categorical_cols = ['Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "\n",
    "# --- Standardize numeric columns ---\n",
    "scaler = StandardScaler()\n",
    "df_numeric = pd.DataFrame(scaler.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# --- One-hot encode categorical columns ---\n",
    "encoder = OneHotEncoder(sparse_output=False)  # updated parameter\n",
    "df_categorical = pd.DataFrame(encoder.fit_transform(df[categorical_cols]),\n",
    "                              columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# --- Combine numeric and categorical transformed data ---\n",
    "df_transformed = pd.concat([df_numeric, df_categorical], axis=1)\n",
    "\n",
    "# --- Part III (a): Similarity between two objects ---\n",
    "obj1 = df_transformed.iloc[0].values\n",
    "obj2 = df_transformed.iloc[1].values\n",
    "\n",
    "# Simple Matching Similarity\n",
    "simple_matching = np.sum(obj1 == obj2) / len(obj1)\n",
    "\n",
    "# Jaccard Similarity (binary attributes only)\n",
    "obj1_bin = df_categorical.iloc[0].values\n",
    "obj2_bin = df_categorical.iloc[1].values\n",
    "jaccard_similarity = np.sum(np.logical_and(obj1_bin, obj2_bin)) / np.sum(np.logical_or(obj1_bin, obj2_bin))\n",
    "\n",
    "# Cosine Similarity (all attributes)\n",
    "cos_sim = cosine_similarity([obj1], [obj2])[0][0]\n",
    "\n",
    "print(\"Simple Matching Similarity:\", simple_matching)\n",
    "print(\"Jaccard Similarity:\", jaccard_similarity)\n",
    "print(\"Cosine Similarity:\", cos_sim)\n",
    "\n",
    "# --- Part III (b): Correlation between two features ---\n",
    "if 'CommuteDistance' in df.columns:\n",
    "    corr, _ = pearsonr(df['CommuteDistance'], df['YearlyIncome'])\n",
    "    print(\"Pearson Correlation between CommuteDistance and YearlyIncome:\", corr)\n",
    "else:\n",
    "    print(\"CommuteDistance column not found in dataset\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
